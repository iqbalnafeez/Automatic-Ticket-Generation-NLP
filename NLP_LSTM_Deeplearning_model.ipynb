{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "8YkpJGuf2r9Q",
    "outputId": "0611219e-2685-41a7-bc1f-269571023052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9bMsdT03A7T"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ftfy translate langdetect imbalanced-learn collections-extended rake_nltk googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPgo2b4TLgE1"
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJm3L9aszMhi"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Capstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AN6WzRlM3M_q"
   },
   "outputs": [],
   "source": [
    "filename= \"/content/drive/My Drive/Capstone/final_dataframe_forDeep_Learning_Model.csv\"\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BW_Oqb9kUUYO"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "MAX_LENGTH = 300\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df8.data.values)\n",
    "post_seq = tokenizer.texts_to_sequences(df8.data.values)\n",
    "post_seq_padded = pad_sequences(post_seq, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVSqd4x8VjvY"
   },
   "outputs": [],
   "source": [
    "y = df8['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEneVCAKUwOR"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(post_seq_padded, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "covPj7AiX3_a"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8DbjU2pb_MW"
   },
   "outputs": [],
   "source": [
    "num_class = len(np.unique(df8['target'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oLMKlOhnbt6W",
    "outputId": "ea23b229-901b-4655-e2bf-ed6e3d9f4f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 300, 128)          2237056   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 69)                2277      \n",
      "=================================================================\n",
      "Total params: 2,290,821\n",
      "Trainable params: 2,290,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21585 samples, validate on 9252 samples\n",
      "Epoch 1/10\n",
      "21585/21585 [==============================] - 215s 10ms/step - loss: 2.7350 - acc: 0.3630 - val_loss: 1.2430 - val_acc: 0.7195\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71952, saving model to weights.hdf5\n",
      "Epoch 2/10\n",
      "21585/21585 [==============================] - 212s 10ms/step - loss: 0.7493 - acc: 0.8252 - val_loss: 0.5638 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71952 to 0.86922, saving model to weights.hdf5\n",
      "Epoch 3/10\n",
      "21585/21585 [==============================] - 211s 10ms/step - loss: 0.3626 - acc: 0.9133 - val_loss: 0.4875 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.86922 to 0.89310, saving model to weights.hdf5\n",
      "Epoch 4/10\n",
      "21585/21585 [==============================] - 211s 10ms/step - loss: 0.2258 - acc: 0.9451 - val_loss: 0.3901 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89310 to 0.91256, saving model to weights.hdf5\n",
      "Epoch 5/10\n",
      "21585/21585 [==============================] - 210s 10ms/step - loss: 0.1592 - acc: 0.9601 - val_loss: 0.4236 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91256\n",
      "Epoch 6/10\n",
      "21585/21585 [==============================] - 211s 10ms/step - loss: 0.1278 - acc: 0.9672 - val_loss: 0.3576 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91256 to 0.92942, saving model to weights.hdf5\n",
      "Epoch 7/10\n",
      "21585/21585 [==============================] - 210s 10ms/step - loss: 0.0857 - acc: 0.9797 - val_loss: 0.3644 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92942\n",
      "Epoch 8/10\n",
      "21585/21585 [==============================] - 210s 10ms/step - loss: 0.0672 - acc: 0.9837 - val_loss: 0.3909 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92942\n",
      "Epoch 9/10\n",
      "21585/21585 [==============================] - 211s 10ms/step - loss: 0.0547 - acc: 0.9871 - val_loss: 0.4573 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92942\n",
      "Epoch 10/10\n",
      "21585/21585 [==============================] - 210s 10ms/step - loss: 0.0714 - acc: 0.9818 - val_loss: 0.4236 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92942\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(MAX_LENGTH, ))\n",
    "embedding_layer = Embedding(vocab_size,\n",
    "                            128,\n",
    "                            input_length=MAX_LENGTH)(inputs)\n",
    "\n",
    "x = LSTM(64)(embedding_layer)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "model = Model(inputs=[inputs], outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "filepath=\"weights.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "history = model.fit([X_train], batch_size=64, y=to_categorical(y_train), verbose=1, validation_split=0.3, \n",
    "          shuffle=True, epochs=10, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "My6jGd0QmKIe",
    "outputId": "3ba00f1e-ce3d-4169-bb09-a19381751789"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9287984261501211"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predicted = model.predict(X_test)\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "accuracy_score(y_test, predicted)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Colab_25GBRAM_GPU_upsampling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
